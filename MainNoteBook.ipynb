{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 18802 records, Total: 18802\n"
     ]
    }
   ],
   "source": [
    "url = \"https://data.cityofnewyork.us/resource/6v4b-5gp4.json\"\n",
    "page = requests.get(url)\n",
    "converted = page.json()\n",
    "\n",
    "# Pull your JSON data programmatically into your Python program, a\n",
    "# and save this object into the path data/json.\n",
    "# Parameters for the API request (limit the number of records per request)\n",
    "params = {\n",
    "    '$limit': 50000,  # Max limit per request\n",
    "}\n",
    "\n",
    "# Function to fetch all data with pagination\n",
    "def fetch_all_data():\n",
    "    all_data = []  # List to store all records\n",
    "    offset = 0  # Starting point (offset)\n",
    "\n",
    "    while True:\n",
    "        # Add the current offset to the parameters\n",
    "        params['$offset'] = offset\n",
    "\n",
    "        # Send the request to the API\n",
    "        response = requests.get(url, params=params)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "\n",
    "            # If there is no data in the response, stop the loop\n",
    "            if not data:\n",
    "                break\n",
    "\n",
    "            # Append the data to the all_data list\n",
    "            all_data.extend(data)\n",
    "\n",
    "            # Print progress (optional, for debugging)\n",
    "            print(f\"Fetched {len(data)} records, Total: {len(all_data)}\")\n",
    "\n",
    "            # Increase the offset by the limit for the next page\n",
    "            offset += 50000\n",
    "        else:\n",
    "            print(f\"Error fetching data: {response.status_code}\")\n",
    "            break\n",
    "\n",
    "    return all_data\n",
    "\n",
    "# Fetch all data with pagination\n",
    "all_data = fetch_all_data()\n",
    "\n",
    "# Convert the data into a pandas DataFrame\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "\n",
    "data_folder_csv = 'csv'\n",
    "os.makedirs(data_folder_csv, exist_ok=True)  # Ensure the folder exists\n",
    "csv_path = os.path.join(data_folder_csv, 'nyc_all_parks_special_event.csv')\n",
    "\n",
    "# Save the DataFrame to a CSV file in the 'data/csv' folder\n",
    "df.to_csv(csv_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
